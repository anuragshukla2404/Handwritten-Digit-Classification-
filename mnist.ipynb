{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = x.to_numpy()[36001]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image,cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x[:60000],x[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test = y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_test = y_test.astype(np.int8)\n",
    "\n",
    "y_train_2 = y_train==2\n",
    "y_test_2 = y_test==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "59995    False\n",
       "59996    False\n",
       "59997    False\n",
       "59998    False\n",
       "59999    False\n",
       "Name: class, Length: 60000, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "0.9885\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train,y_train_2)\n",
    "example = clf.predict([some_digit])\n",
    "print(example)\n",
    "print(clf.score(x_test,y_test_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9702\n",
      "[ True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train_2)\n",
    "example_dt = clf.predict([some_digit])\n",
    "print(dt.score(x_test,y_test_2))\n",
    "print(example_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier()\n",
    "gbclf.fit(x_train,y_train_2)\n",
    "example_gbclf = gbclf.predict([some_digit])\n",
    "print(gbclf.score(x_test,y_test_2))\n",
    "print(example_gbclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802\n",
      "[ True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train_2)\n",
    "example_lr = lr.predict([some_digit])\n",
    "print(lr.score(x_test,y_test_2))\n",
    "print(example_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier()\n",
    "abclf.fit(x_train,y_train_2)\n",
    "example_abclf =abclf.predict([some_digit])\n",
    "print(abclf.score(x_test,y_test_2))\n",
    "print(example_abclf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9942\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier()\n",
    "xgbclf.fit(x_train,y_train_2)\n",
    "example_xgbclf =xgbclf.predict([some_digit])\n",
    "print(xgbclf.score(x_test,y_test_2))\n",
    "print(example_xgbclf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinod\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9947\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train,y_train_2)\n",
    "example_svc = svc.predict([some_digit])\n",
    "print(svc.score(x_test,y_test_2))\n",
    "print(example_svc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "a = cross_val_score(svc, x_train, y_train_2, cv=3, scoring=\"accuracy\")\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.994 , 0.9937, 0.9937])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = True,\n",
    "    transform= ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = False,\n",
    "    transform= ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train':DataLoader(train_data,\n",
    "                       batch_size=120,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1),\n",
    "\n",
    "    'test':DataLoader(test_data,\n",
    "                       batch_size=120,\n",
    "                       shuffle=True,\n",
    "                       num_workers=1) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop=nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x =F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Mnet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(loaders['train']):\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss= loss_fn(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx*len(data)}/{len(loaders[\"train\"].dataset)} ({100 *  batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in loaders['test']:\n",
    "            data,target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss +=loss_fn(output,target).item()\n",
    "            pred= output.argmax(dim=1,keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'n/ Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod\\AppData\\Local\\Temp\\ipykernel_2296\\1203378447.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.302708\n",
      "Train Epoch: 1 [1200/60000 (2%)]\t2.299161\n",
      "Train Epoch: 1 [2400/60000 (4%)]\t2.291858\n",
      "Train Epoch: 1 [3600/60000 (6%)]\t2.259159\n",
      "Train Epoch: 1 [4800/60000 (8%)]\t2.148603\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.045941\n",
      "Train Epoch: 1 [7200/60000 (12%)]\t1.948210\n",
      "Train Epoch: 1 [8400/60000 (14%)]\t1.875971\n",
      "Train Epoch: 1 [9600/60000 (16%)]\t1.885118\n",
      "Train Epoch: 1 [10800/60000 (18%)]\t1.804145\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.768639\n",
      "Train Epoch: 1 [13200/60000 (22%)]\t1.755316\n",
      "Train Epoch: 1 [14400/60000 (24%)]\t1.771452\n",
      "Train Epoch: 1 [15600/60000 (26%)]\t1.755649\n",
      "Train Epoch: 1 [16800/60000 (28%)]\t1.709368\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.718523\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t1.744325\n",
      "Train Epoch: 1 [20400/60000 (34%)]\t1.728251\n",
      "Train Epoch: 1 [21600/60000 (36%)]\t1.722542\n",
      "Train Epoch: 1 [22800/60000 (38%)]\t1.711924\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.677057\n",
      "Train Epoch: 1 [25200/60000 (42%)]\t1.698696\n",
      "Train Epoch: 1 [26400/60000 (44%)]\t1.676040\n",
      "Train Epoch: 1 [27600/60000 (46%)]\t1.662891\n",
      "Train Epoch: 1 [28800/60000 (48%)]\t1.701661\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.637446\n",
      "Train Epoch: 1 [31200/60000 (52%)]\t1.675743\n",
      "Train Epoch: 1 [32400/60000 (54%)]\t1.654896\n",
      "Train Epoch: 1 [33600/60000 (56%)]\t1.626873\n",
      "Train Epoch: 1 [34800/60000 (58%)]\t1.639740\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.642336\n",
      "Train Epoch: 1 [37200/60000 (62%)]\t1.639239\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t1.702513\n",
      "Train Epoch: 1 [39600/60000 (66%)]\t1.632235\n",
      "Train Epoch: 1 [40800/60000 (68%)]\t1.671888\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.634023\n",
      "Train Epoch: 1 [43200/60000 (72%)]\t1.643262\n",
      "Train Epoch: 1 [44400/60000 (74%)]\t1.670414\n",
      "Train Epoch: 1 [45600/60000 (76%)]\t1.596307\n",
      "Train Epoch: 1 [46800/60000 (78%)]\t1.624114\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.649841\n",
      "Train Epoch: 1 [49200/60000 (82%)]\t1.616831\n",
      "Train Epoch: 1 [50400/60000 (84%)]\t1.667818\n",
      "Train Epoch: 1 [51600/60000 (86%)]\t1.625137\n",
      "Train Epoch: 1 [52800/60000 (88%)]\t1.644513\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.573391\n",
      "Train Epoch: 1 [55200/60000 (92%)]\t1.616378\n",
      "Train Epoch: 1 [56400/60000 (94%)]\t1.621046\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t1.585838\n",
      "Train Epoch: 1 [58800/60000 (98%)]\t1.609971\n",
      "n/ Test set: Average loss: 0.0129, Accuracy: 9242/10000 (92%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.669670\n",
      "Train Epoch: 2 [1200/60000 (2%)]\t1.718092\n",
      "Train Epoch: 2 [2400/60000 (4%)]\t1.601385\n",
      "Train Epoch: 2 [3600/60000 (6%)]\t1.604918\n",
      "Train Epoch: 2 [4800/60000 (8%)]\t1.599709\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.576945\n",
      "Train Epoch: 2 [7200/60000 (12%)]\t1.571807\n",
      "Train Epoch: 2 [8400/60000 (14%)]\t1.681158\n",
      "Train Epoch: 2 [9600/60000 (16%)]\t1.618623\n",
      "Train Epoch: 2 [10800/60000 (18%)]\t1.594948\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.559584\n",
      "Train Epoch: 2 [13200/60000 (22%)]\t1.621436\n",
      "Train Epoch: 2 [14400/60000 (24%)]\t1.554406\n",
      "Train Epoch: 2 [15600/60000 (26%)]\t1.596146\n",
      "Train Epoch: 2 [16800/60000 (28%)]\t1.615959\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.570559\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t1.613772\n",
      "Train Epoch: 2 [20400/60000 (34%)]\t1.569283\n",
      "Train Epoch: 2 [21600/60000 (36%)]\t1.616106\n",
      "Train Epoch: 2 [22800/60000 (38%)]\t1.567907\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.610952\n",
      "Train Epoch: 2 [25200/60000 (42%)]\t1.604833\n",
      "Train Epoch: 2 [26400/60000 (44%)]\t1.581563\n",
      "Train Epoch: 2 [27600/60000 (46%)]\t1.556429\n",
      "Train Epoch: 2 [28800/60000 (48%)]\t1.561060\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.704529\n",
      "Train Epoch: 2 [31200/60000 (52%)]\t1.614533\n",
      "Train Epoch: 2 [32400/60000 (54%)]\t1.631910\n",
      "Train Epoch: 2 [33600/60000 (56%)]\t1.569260\n",
      "Train Epoch: 2 [34800/60000 (58%)]\t1.592699\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.648603\n",
      "Train Epoch: 2 [37200/60000 (62%)]\t1.608934\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t1.547106\n",
      "Train Epoch: 2 [39600/60000 (66%)]\t1.564789\n",
      "Train Epoch: 2 [40800/60000 (68%)]\t1.532688\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.602034\n",
      "Train Epoch: 2 [43200/60000 (72%)]\t1.583881\n",
      "Train Epoch: 2 [44400/60000 (74%)]\t1.569567\n",
      "Train Epoch: 2 [45600/60000 (76%)]\t1.588043\n",
      "Train Epoch: 2 [46800/60000 (78%)]\t1.562718\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.583914\n",
      "Train Epoch: 2 [49200/60000 (82%)]\t1.611918\n",
      "Train Epoch: 2 [50400/60000 (84%)]\t1.581280\n",
      "Train Epoch: 2 [51600/60000 (86%)]\t1.636423\n",
      "Train Epoch: 2 [52800/60000 (88%)]\t1.596473\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.580784\n",
      "Train Epoch: 2 [55200/60000 (92%)]\t1.622324\n",
      "Train Epoch: 2 [56400/60000 (94%)]\t1.551026\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t1.552651\n",
      "Train Epoch: 2 [58800/60000 (98%)]\t1.577961\n",
      "n/ Test set: Average loss: 0.0128, Accuracy: 9412/10000 (94%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.590053\n",
      "Train Epoch: 3 [1200/60000 (2%)]\t1.612809\n",
      "Train Epoch: 3 [2400/60000 (4%)]\t1.643800\n",
      "Train Epoch: 3 [3600/60000 (6%)]\t1.565108\n",
      "Train Epoch: 3 [4800/60000 (8%)]\t1.583776\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.573576\n",
      "Train Epoch: 3 [7200/60000 (12%)]\t1.610007\n",
      "Train Epoch: 3 [8400/60000 (14%)]\t1.563828\n",
      "Train Epoch: 3 [9600/60000 (16%)]\t1.587607\n",
      "Train Epoch: 3 [10800/60000 (18%)]\t1.557080\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.600424\n",
      "Train Epoch: 3 [13200/60000 (22%)]\t1.541748\n",
      "Train Epoch: 3 [14400/60000 (24%)]\t1.588706\n",
      "Train Epoch: 3 [15600/60000 (26%)]\t1.607576\n",
      "Train Epoch: 3 [16800/60000 (28%)]\t1.577465\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.562834\n",
      "Train Epoch: 3 [19200/60000 (32%)]\t1.574921\n",
      "Train Epoch: 3 [20400/60000 (34%)]\t1.611512\n",
      "Train Epoch: 3 [21600/60000 (36%)]\t1.559861\n",
      "Train Epoch: 3 [22800/60000 (38%)]\t1.545970\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.579973\n",
      "Train Epoch: 3 [25200/60000 (42%)]\t1.592329\n",
      "Train Epoch: 3 [26400/60000 (44%)]\t1.580305\n",
      "Train Epoch: 3 [27600/60000 (46%)]\t1.575586\n",
      "Train Epoch: 3 [28800/60000 (48%)]\t1.578727\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.555310\n",
      "Train Epoch: 3 [31200/60000 (52%)]\t1.584889\n",
      "Train Epoch: 3 [32400/60000 (54%)]\t1.523508\n",
      "Train Epoch: 3 [33600/60000 (56%)]\t1.586406\n",
      "Train Epoch: 3 [34800/60000 (58%)]\t1.590481\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.560329\n",
      "Train Epoch: 3 [37200/60000 (62%)]\t1.575166\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t1.552177\n",
      "Train Epoch: 3 [39600/60000 (66%)]\t1.609462\n",
      "Train Epoch: 3 [40800/60000 (68%)]\t1.539006\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.629276\n",
      "Train Epoch: 3 [43200/60000 (72%)]\t1.620032\n",
      "Train Epoch: 3 [44400/60000 (74%)]\t1.563358\n",
      "Train Epoch: 3 [45600/60000 (76%)]\t1.575670\n",
      "Train Epoch: 3 [46800/60000 (78%)]\t1.569189\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.579149\n",
      "Train Epoch: 3 [49200/60000 (82%)]\t1.545313\n",
      "Train Epoch: 3 [50400/60000 (84%)]\t1.595419\n",
      "Train Epoch: 3 [51600/60000 (86%)]\t1.563717\n",
      "Train Epoch: 3 [52800/60000 (88%)]\t1.518802\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.576408\n",
      "Train Epoch: 3 [55200/60000 (92%)]\t1.522687\n",
      "Train Epoch: 3 [56400/60000 (94%)]\t1.586094\n",
      "Train Epoch: 3 [57600/60000 (96%)]\t1.573868\n",
      "Train Epoch: 3 [58800/60000 (98%)]\t1.606994\n",
      "n/ Test set: Average loss: 0.0127, Accuracy: 9479/10000 (95%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.627359\n",
      "Train Epoch: 4 [1200/60000 (2%)]\t1.558507\n",
      "Train Epoch: 4 [2400/60000 (4%)]\t1.519197\n",
      "Train Epoch: 4 [3600/60000 (6%)]\t1.586906\n",
      "Train Epoch: 4 [4800/60000 (8%)]\t1.563100\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.572478\n",
      "Train Epoch: 4 [7200/60000 (12%)]\t1.556915\n",
      "Train Epoch: 4 [8400/60000 (14%)]\t1.566202\n",
      "Train Epoch: 4 [9600/60000 (16%)]\t1.566216\n",
      "Train Epoch: 4 [10800/60000 (18%)]\t1.619542\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.541237\n",
      "Train Epoch: 4 [13200/60000 (22%)]\t1.565127\n",
      "Train Epoch: 4 [14400/60000 (24%)]\t1.560199\n",
      "Train Epoch: 4 [15600/60000 (26%)]\t1.542523\n",
      "Train Epoch: 4 [16800/60000 (28%)]\t1.600128\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.596308\n",
      "Train Epoch: 4 [19200/60000 (32%)]\t1.599171\n",
      "Train Epoch: 4 [20400/60000 (34%)]\t1.581635\n",
      "Train Epoch: 4 [21600/60000 (36%)]\t1.535430\n",
      "Train Epoch: 4 [22800/60000 (38%)]\t1.524032\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.610598\n",
      "Train Epoch: 4 [25200/60000 (42%)]\t1.592778\n",
      "Train Epoch: 4 [26400/60000 (44%)]\t1.581219\n",
      "Train Epoch: 4 [27600/60000 (46%)]\t1.498879\n",
      "Train Epoch: 4 [28800/60000 (48%)]\t1.588504\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.570825\n",
      "Train Epoch: 4 [31200/60000 (52%)]\t1.574533\n",
      "Train Epoch: 4 [32400/60000 (54%)]\t1.546899\n",
      "Train Epoch: 4 [33600/60000 (56%)]\t1.542253\n",
      "Train Epoch: 4 [34800/60000 (58%)]\t1.555282\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.521881\n",
      "Train Epoch: 4 [37200/60000 (62%)]\t1.564871\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t1.532158\n",
      "Train Epoch: 4 [39600/60000 (66%)]\t1.538327\n",
      "Train Epoch: 4 [40800/60000 (68%)]\t1.550402\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.580833\n",
      "Train Epoch: 4 [43200/60000 (72%)]\t1.560317\n",
      "Train Epoch: 4 [44400/60000 (74%)]\t1.582713\n",
      "Train Epoch: 4 [45600/60000 (76%)]\t1.557717\n",
      "Train Epoch: 4 [46800/60000 (78%)]\t1.574209\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.527675\n",
      "Train Epoch: 4 [49200/60000 (82%)]\t1.555936\n",
      "Train Epoch: 4 [50400/60000 (84%)]\t1.597003\n",
      "Train Epoch: 4 [51600/60000 (86%)]\t1.552278\n",
      "Train Epoch: 4 [52800/60000 (88%)]\t1.567564\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.595634\n",
      "Train Epoch: 4 [55200/60000 (92%)]\t1.576244\n",
      "Train Epoch: 4 [56400/60000 (94%)]\t1.567481\n",
      "Train Epoch: 4 [57600/60000 (96%)]\t1.531353\n",
      "Train Epoch: 4 [58800/60000 (98%)]\t1.527975\n",
      "n/ Test set: Average loss: 0.0126, Accuracy: 9593/10000 (96%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod\\AppData\\Local\\Temp\\ipykernel_2296\\1203378447.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[10]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f'prediction: {prediction}')\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image,cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
